{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086ee0d1",
   "metadata": {},
   "source": [
    "This notebook aims to compare the results of entropic OTC and exact OTC, demonstrating that the entropic OTC converges to the exact OTC. Two examples are provided to illustrate this convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173eaa98",
   "metadata": {},
   "source": [
    "Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79455418-ae8c-4944-92df-9ddb46bfc348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100 connected networks.\n",
      "Success rate: 80.00%\n",
      "Graph labels: [11.85 16.05 17.85 18.5  14.37 15.4  14.36 18.59 18.23 16.55  8.05 12.\n",
      " 11.44 14.46 11.91 16.61 20.83 12.14 15.37 13.11 18.56 19.06  9.51  6.31\n",
      " 12.39 14.08 20.44 15.8  15.77 16.93 15.91  9.63 16.73 11.48 17.99  9.74\n",
      " 17.23 15.63 13.39 17.48 15.93 11.53 19.55 10.79 10.59 12.69  6.41 22.56\n",
      " 14.11  8.9  11.92 10.26 15.42 11.96 18.64 13.33 14.07 11.12 19.68 22.2\n",
      " 11.76 13.47 14.42 23.14 11.94 17.48 16.33 12.02 12.   20.8  12.6  15.8\n",
      " 16.8  15.25 13.27 24.46 26.92 10.78 16.4  12.3  12.7  13.93 18.33 17.76\n",
      " 13.83 14.18 12.46 10.98 11.39 11.3  16.08 11.76 18.15 14.05 19.41 22.02\n",
      " 11.41 17.2  12.87 14.83]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.special\n",
    "\n",
    "def generate_connected_networks_with_node_features(seed, num_networks, poisson_lambda, node_means, node_variances, edge_lambda):\n",
    "    # Set a random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Initialize empty lists\n",
    "    adj_list = []\n",
    "    node_feat_list = []\n",
    "\n",
    "    # Initialize counter for total attempts\n",
    "    total_attempts = 0\n",
    "\n",
    "    def generate_connected_adjacency_matrix(n, edge_lambda):\n",
    "        # Sample the expected number of edges for each node\n",
    "        expected_edges = np.random.poisson(edge_lambda, size=n)\n",
    "        \n",
    "        # Calculate the probability of edge formation for each direction\n",
    "        p = expected_edges / (n - 1)\n",
    "        \n",
    "        # Initialize adjacency matrix\n",
    "        A = np.zeros((n, n), dtype=int)\n",
    "        \n",
    "        # Sample edges\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                A[i, j] = np.random.binomial(1, p[i])\n",
    "                A[j, i] = np.random.binomial(1, p[j])\n",
    "        \n",
    "        # Final adjacency matrix where adj[i, j] = A[i, j] + A[j, i]\n",
    "        adj = A + A.T\n",
    "\n",
    "        # Ensure no self-loops\n",
    "        np.fill_diagonal(adj, 0)\n",
    "\n",
    "        return adj\n",
    "\n",
    "    while len(adj_list) < num_networks:\n",
    "        # Increment total attempts\n",
    "        total_attempts += 1\n",
    "        \n",
    "        # Sample an integer n from Poisson distribution with given lambda\n",
    "        n = np.random.poisson(poisson_lambda)\n",
    "        \n",
    "        # Generate the adjacency matrix adj\n",
    "        adj = generate_connected_adjacency_matrix(n, edge_lambda)\n",
    "        \n",
    "        # Check if adj is connected\n",
    "        G = nx.from_numpy_array(adj)\n",
    "        if nx.is_connected(G):\n",
    "            adj_list.append(adj)\n",
    "            \n",
    "            # Generate node features with the specified means and variances\n",
    "            node_feat = np.column_stack([\n",
    "                np.random.normal(mean, np.sqrt(var), n)\n",
    "                for mean, var in zip(node_means, node_variances)\n",
    "            ])\n",
    "            \n",
    "            # Round the elements in node_feat to 2 decimal places\n",
    "            node_feat = np.round(node_feat, 2)\n",
    "            \n",
    "            node_feat_list.append(node_feat)\n",
    "\n",
    "    # Calculate success rate\n",
    "    success_rate = len(adj_list) / total_attempts\n",
    "\n",
    "    return adj_list, node_feat_list, success_rate\n",
    "\n",
    "def graph_convolution(adj_list, node_feat_list):\n",
    "    conv_results = []\n",
    "    \n",
    "    for adj, X in zip(adj_list, node_feat_list):\n",
    "        n = adj.shape[0]\n",
    "        I = np.eye(n)\n",
    "        adj_hat = adj + I\n",
    "        D = np.diag(np.sum(adj_hat, axis=1))\n",
    "        D_inv_sqrt = np.linalg.inv(np.sqrt(D))\n",
    "        X_conv = D_inv_sqrt @ adj_hat @ D_inv_sqrt @ X\n",
    "        conv_results.append(X_conv.mean(axis=0))\n",
    "        \n",
    "    return conv_results\n",
    "\n",
    "def generate_graph_discrete_labels(adj_list, node_feat_list, coeffs, error_variance, seed):\n",
    "    np.random.seed(seed)\n",
    "    conv_results = graph_convolution(adj_list, node_feat_list)\n",
    "    graph_labels = []\n",
    "    \n",
    "    for conv_result in conv_results:\n",
    "        linear_combination = np.dot(conv_result, coeffs)\n",
    "        error = np.random.normal(0, np.sqrt(error_variance))\n",
    "        label_prob = scipy.special.expit(linear_combination + error)\n",
    "        label = np.random.binomial(1, label_prob)\n",
    "        graph_labels.append(label)\n",
    "    \n",
    "    return graph_labels\n",
    "\n",
    "def generate_graph_continuous_labels(adj_list, node_feat_list, coeffs, error_variance, seed):\n",
    "    np.random.seed(seed)\n",
    "    conv_results = graph_convolution(adj_list, node_feat_list)\n",
    "    graph_labels = []\n",
    "    \n",
    "    for conv_result in conv_results:\n",
    "        linear_combination = np.dot(conv_result, coeffs)\n",
    "        error = np.random.normal(0, np.sqrt(error_variance))\n",
    "        label = linear_combination + error\n",
    "        graph_labels.append(label)\n",
    "    \n",
    "    return graph_labels\n",
    "\n",
    "# Example usage\n",
    "seed = 921\n",
    "num_networks = 100\n",
    "poisson_lambda = 35\n",
    "edge_lambda = 3  # Expected number of edges for each node\n",
    "node_means = [9, 7, 10]  # Means for each feature column\n",
    "node_variances = [16, 9, 25]  # Variances for each feature column\n",
    "\n",
    "adj_list, node_feat_list, success_rate = generate_connected_networks_with_node_features(seed, num_networks, poisson_lambda, node_means, node_variances, edge_lambda)\n",
    "\n",
    "# Coefficients for the linear combination of conv_results\n",
    "coeffs = [4, -3, 0]\n",
    "error_variance = 2.5\n",
    "\n",
    "graph_labels = generate_graph_continuous_labels(adj_list, node_feat_list, coeffs, error_variance, seed)\n",
    "graph_labels = np.round(graph_labels, 2)\n",
    "\n",
    "# Output the number of generated networks, the success rate, and graph labels\n",
    "print(f\"Generated {len(adj_list)} connected networks.\")\n",
    "print(f\"Success rate: {success_rate:.2%}\")\n",
    "print(f\"Graph labels: {graph_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0869ea72-007f-4486-8d5a-cd3a619d58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entropic_otc import entropic_otc\n",
    "from exact_otc import exact_otc\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d791c0-ff4c-4e75-9915-cc041fa9f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_list = [utils.adj_to_trans1(A) for A in adj_list]\n",
    "feat1_list = [x[:,0] for x in node_feat_list]\n",
    "feat2_list = [x[:,1] for x in node_feat_list]\n",
    "feat3_list = [x[:,2] for x in node_feat_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca766c89",
   "metadata": {},
   "source": [
    "- L = 25, T = 50, xi = 0.1, sink_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c65ca20-4739-4295-a9fb-c9c3a4f1cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.8563480377197266 seconds\n",
      "Elapsed time: 4.662265777587891 seconds\n",
      "Elapsed time: 3.7100069522857666 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17.024085467032634, 17.023989168598455, 10.850993850826315)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = utils.get_sq_cost(feat1_list[3], feat1_list[6])\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "[result_e1, P_e1, stat_dist_e1] = entropic_otc(P_list[3], P_list[6], cost, get_sd = False, L = 25, T = 50, xi = 0.1, sink_iter = 10)\n",
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "[result_e2, P_e2, stat_dist_e2] = entropic_otc(P_list[3], P_list[6], cost, get_sd = True, L = 25, T = 50, xi = 0.1, sink_iter = 10)\n",
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "[result_n, P_n, stat_dist_n] = exact_otc(P_list[3], P_list[6], cost)\n",
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time} seconds\")\n",
    "\n",
    "result_e1, result_e2, result_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495b7b2",
   "metadata": {},
   "source": [
    "- L = 25, T = 50, xi = 1, sink_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c7693-6c88-4e3b-b0e2-26858c6e3084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 11.05821704864502 seconds\n",
      "13.658963944342535\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "[result, P, stat_dist] = entropic_otc(P_list[3], P_list[6], cost, get_sd = True, L = 25, T = 50, xi = 1, sink_iter = 100)\n",
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time} seconds\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df240b",
   "metadata": {},
   "source": [
    "- L = 25, T = 50, xi = 1, sink_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10b0ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 85.70026803016663 seconds\n",
      "10.955095752170038\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "[result, P, stat_dist] = entropic_otc(P_list[3], P_list[6], cost, get_sd = True, L = 25, T = 50, xi = 1, sink_iter = 1000)\n",
    "end_time = time.time()\n",
    "print(f\"Elapsed time: {end_time - start_time} seconds\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d7514",
   "metadata": {},
   "source": [
    "Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7083b13b-a347-43c1-bcc7-20588393ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15\n",
    "\n",
    "A1 = np.zeros((n + 1, n + 1), dtype=int)\n",
    "A1[1:(n + 1), 0] = 1\n",
    "A1[2:(n + 1), 1:n] = np.eye(n - 1, dtype=int)\n",
    "A1[n, 1] = 1\n",
    "A1 = A1 + A1.T\n",
    "\n",
    "A2 = A1.copy()\n",
    "A2[1, 2] = 0\n",
    "A2[2, 1] = 0\n",
    "\n",
    "A3 = A1.copy()\n",
    "A3[0, 1] = 0\n",
    "A3[1, 0] = 0\n",
    "\n",
    "P1 = utils.adj_to_trans1(A1)\n",
    "P2 = utils.adj_to_trans1(A2)\n",
    "P3 = utils.adj_to_trans1(A3)\n",
    "\n",
    "c12 = utils.get_degree_cost(A1, A2)\n",
    "c13 = utils.get_degree_cost(A1, A3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8a3ef0-6411-482d-85d5-188500dd3b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5517241379310405, 2.6551724137931036)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result_12, P12, stat_dist_12] = exact_otc(P1, P2, c12)\n",
    "[result_13, P13, stat_dist_13] = exact_otc(P1, P3, c13)\n",
    "result_12, result_13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afaedeb",
   "metadata": {},
   "source": [
    "- L = 25, T = 50, xi = 0.1, sink_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3393f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.553874249034113, 2.655272554155938)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result_e12, Pe12, stat_dist_e12] = entropic_otc(P1, P2, c12, get_sd = True, L = 25, T = 50, xi = 0.1, sink_iter = 10)\n",
    "[result_e13, Pe13, stat_dist_e13] = entropic_otc(P1, P3, c13, get_sd = True, L = 25, T = 50, xi = 0.1, sink_iter = 10)\n",
    "result_e12, result_e13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261cd48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NetOTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
